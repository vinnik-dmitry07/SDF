{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import scipy.ndimage\n",
    "from modules import *\n",
    "from meta_modules import *\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignedDistanceTransform:\n",
    "    def __call__(self, img_tensor):\n",
    "        # Threshold.\n",
    "        img_tensor[img_tensor<0.5] = 0.\n",
    "        img_tensor[img_tensor>=0.5] = 1.\n",
    "\n",
    "        # Compute signed distances with distance transform\n",
    "        img_tensor = img_tensor.numpy()\n",
    "\n",
    "        neg_distances = scipy.ndimage.morphology.distance_transform_edt(img_tensor)\n",
    "        sd_img = img_tensor - 1.\n",
    "        sd_img = sd_img.astype(np.uint8)\n",
    "        signed_distances = scipy.ndimage.morphology.distance_transform_edt(sd_img) - neg_distances\n",
    "        signed_distances /= float(img_tensor.shape[1])\n",
    "        signed_distances = torch.Tensor(signed_distances)\n",
    "\n",
    "        return signed_distances, torch.Tensor(img_tensor)\n",
    "\n",
    "def get_mgrid(sidelen):\n",
    "    # Generate 2D pixel coordinates from an image of sidelen x sidelen\n",
    "    pixel_coords = np.stack(np.mgrid[:sidelen,:sidelen], axis=-1)[None,...].astype(np.float32)\n",
    "    pixel_coords /= sidelen    \n",
    "    pixel_coords -= 0.5\n",
    "    pixel_coords = torch.Tensor(pixel_coords).view(-1, 2)\n",
    "    return pixel_coords\n",
    "\n",
    "class MNISTSDFDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, split, size=(256,256)):\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(size),\n",
    "            transforms.ToTensor(),\n",
    "            SignedDistanceTransform(),\n",
    "        ])\n",
    "        self.img_dataset = torchvision.datasets.MNIST('./datasets/MNIST', train=True if split == 'train' else False,\n",
    "                                                download=True)\n",
    "        self.meshgrid = get_mgrid(size[0])\n",
    "        self.im_size = size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_dataset)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img, digit_class = self.img_dataset[item]\n",
    "\n",
    "        signed_distance_img, binary_image = self.transform(img)\n",
    "        \n",
    "        coord_values = self.meshgrid.reshape(-1, 2)\n",
    "        signed_distance_values = signed_distance_img.reshape((-1, 1))\n",
    "        \n",
    "        indices = torch.randperm(coord_values.shape[0])\n",
    "        support_indices = indices[:indices.shape[0]//2]\n",
    "        query_indices = indices[indices.shape[0]//2:]\n",
    "\n",
    "        meta_dict = {'context': (coord_values[support_indices], signed_distance_values[support_indices]), 'query': (coord_values[query_indices], signed_distance_values[query_indices]), 'all': (coord_values, signed_distance_values)}\n",
    "\n",
    "        return meta_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNISTSDFDataset('train', size=(64, 64))\n",
    "val_dataset = MNISTSDFDataset('val', size=(64, 64))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdf_loss(predictions, gt, **kwargs):\n",
    "    return ((predictions - gt)**2).mean()\n",
    "\n",
    "\n",
    "def inner_maml_sdf_loss(predictions, gt, **kwargs):\n",
    "    return ((predictions - gt)**2).sum(0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin2img(tensor):\n",
    "    batch_size, num_samples, channels = tensor.shape\n",
    "    sidelen = np.sqrt(num_samples).astype(int)\n",
    "    return tensor.permute(0,2,1).view(batch_size, channels, sidelen, sidelen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Model\n",
    "\n",
    "For this task, we use a simple model with two hidden layers of 256 hidden units. We use the original MAML algorithm with 3 steps and a single learnable LR initialized to 1e-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypo_module = ReLUFC(in_features=2, out_features=1, \n",
    "                     num_hidden_layers=2, hidden_features=256)\n",
    "hypo_module.net.apply(sal_init)\n",
    "hypo_module.net[-1].apply(sal_init_last_layer)\n",
    "\n",
    "model = MetaSDF(hypo_module, inner_maml_sdf_loss, init_lr=1e-1, \n",
    "                     lr_type='global', first_order=False).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(lr=1e-4, params=model.parameters())\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(3):\n",
    "    for step, meta_batch in enumerate(train_dataloader):\n",
    "        model.train()        \n",
    "        context_x, context_y = meta_batch['context']\n",
    "        query_x = meta_batch['query'][0]\n",
    "\n",
    "        context_x = context_x.cuda()\n",
    "        context_y = context_y.cuda()\n",
    "        query_x = query_x.cuda()\n",
    "\n",
    "        # Adapt model using context examples\n",
    "        fast_params = model.generate_params(context_x, context_y)\n",
    "        \n",
    "        # Use the adapted examples to make predictions on query\n",
    "        pred_sd = model.forward_with_params(query_x, fast_params)\n",
    "        \n",
    "        # Calculate loss on query examples\n",
    "        loss = sdf_loss(pred_sd, meta_batch['query'][1].cuda())\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if step % 1000 == 0:\n",
    "            with torch.no_grad():\n",
    "                pred_image = model.forward_with_params(meta_batch['all'][0].cuda(), fast_params)\n",
    "            print(f\"Epoch: {epoch} \\t step: {step} \\t loss: {loss.item()}\")\n",
    "            plt.imshow(lin2img(pred_image).cpu().numpy()[0][0])\n",
    "            plt.show()\n",
    "\n",
    "    print(\"Evaluating model\")\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for step, meta_batch in enumerate(val_dataloader):\n",
    "            # Instead of explicitly calling generate_params and forward_with_params,\n",
    "            # we can pass the meta_batch dictionary to the model's forward method\n",
    "            pred_sd, _ = model(meta_batch)\n",
    "            val_loss = sdf_loss(pred_sd, meta_batch['query'][1].cuda())\n",
    "            val_losses.append(val_loss.item())\n",
    "            \n",
    "            if step % 1000 == 0:\n",
    "                pred_image = model.forward_with_params(meta_batch['all'][0].cuda(), fast_params)\n",
    "                print(f\"Val Image -- Epoch: {epoch} \\t step: {step} \\t loss: {loss.item()}\")\n",
    "                plt.imshow(lin2img(pred_image).cpu().numpy()[0][0])\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
